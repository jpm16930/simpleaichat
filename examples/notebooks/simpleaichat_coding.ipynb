{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jfTDBnMbGO3"
      },
      "source": [
        "# Efficient Coding Assistant with simpleaichat\n",
        "\n",
        "Many coders use ChatGPT for coding help, however the web interface can be slow and contain unnecessary discussion when you want code. With some system prompt engineering and simplechatapi streaming, you can cut down code time generation and costs significantly.\n",
        "\n",
        "**DISCLAIMER: Your mileage may vary in terms of code quality and accuracy in practice, but this is a good, hackable starting point.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5ZeSKyedacCE"
      },
      "outputs": [],
      "source": [
        "!pip install -q simpleaichat\n",
        "\n",
        "from simpleaichat import AIChat\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kXTv7zXapit"
      },
      "source": [
        "For the following cell, input your OpenAI API key when prompted. **It will not be saved to the notebook**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_3QIHtnaqdw",
        "outputId": "34e49b34-83ca-4503-a423-908f334bafac"
      },
      "outputs": [],
      "source": [
        "api_key = getpass(\"OpenAI Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mxBkiR9FacCF"
      },
      "outputs": [],
      "source": [
        "params = {\"temperature\": 0.0}  # for reproducibility\n",
        "model = \"gpt-3.5-turbo\"  # in production, may want to use model=\"gpt-4\" if have access\n",
        "\n",
        "ai = AIChat(api_key=api_key, console=False, params=params, model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4eVxf3Jawo_"
      },
      "source": [
        "Let's start with a simple `is_palindrome()` function in Python, and track how long it takes to run. The output of this should be similar to what is shown in the ChatGPT webapp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCkboiHsacCG",
        "outputId": "cc7d5a48-9383-4296-ac3c-4aeeaa9fae7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure, here's an example implementation of an `is_palindrome()` function in Python:\n",
            "\n",
            "```python\n",
            "def is_palindrome(s):\n",
            "    \"\"\"\n",
            "    Returns True if the given string s is a palindrome, False otherwise.\n",
            "    \"\"\"\n",
            "    # Remove any non-alphanumeric characters and convert to lowercase\n",
            "    s = ''.join(c for c in s if c.isalnum()).lower()\n",
            "    # Check if the string is equal to its reverse\n",
            "    return s == s[::-1]\n",
            "```\n",
            "\n",
            "This function takes a string `s` as input and returns `True` if it is a palindrome (i.e. reads the same forwards and backwards), and `False` otherwise. The function first removes any non-alphanumeric characters from the string and converts it to lowercase, then checks if the resulting string is equal to its reverse using Python's slice notation (`[::-1]` returns the string in reverse order).\n",
            "CPU times: user 5.16 ms, sys: 2.34 ms, total: 7.5 ms\n",
            "Wall time: 7.89 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = ai(\"Write an is_palindrome() function in Python.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBOCM4LMbz3C"
      },
      "source": [
        "That's the typical implementation. However, there's a trick to cut the processing time in half, well known by technical hiring managers who want to trip up prospective candidates.\n",
        "\n",
        "ChatGPT outputs the statistically most common implementation, but it's not necessairily the best. A second pass allows ChatGPT to refine its output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwsfrcPHacCH",
        "outputId": "d906f312-8062-49d5-870b-5c09a6cc6f35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here's an optimized version of the `is_palindrome()` function that avoids creating a new string and uses a loop to compare the characters at each end of the string:\n",
            "\n",
            "```python\n",
            "def is_palindrome(s):\n",
            "    \"\"\"\n",
            "    Returns True if the given string s is a palindrome, False otherwise.\n",
            "    \"\"\"\n",
            "    # Convert to lowercase and remove non-alphanumeric characters\n",
            "    s = ''.join(c for c in s.lower() if c.isalnum())\n",
            "    # Compare characters at each end of the string\n",
            "    for i in range(len(s) // 2):\n",
            "        if s[i] != s[-i-1]:\n",
            "            return False\n",
            "    return True\n",
            "```\n",
            "\n",
            "This version of the function still removes non-alphanumeric characters and converts the string to lowercase, but instead of creating a new string to check for equality with its reverse, it uses a loop to compare the characters at each end of the string. The loop only needs to iterate over half of the string (using integer division `//` to get the floor of the length divided by 2), since the other half is symmetric. If any pair of characters doesn't match, the function immediately returns `False`. If the loop completes without finding any mismatches, the function returns `True`. This approach avoids creating a new string and is more efficient for long strings.\n",
            "CPU times: user 4.63 ms, sys: 1.98 ms, total: 6.61 ms\n",
            "Wall time: 11.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = ai(\"Make it more efficient.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWRKL30uacCH",
        "outputId": "d77516d3-f873-4a4c-b38c-3fd09086d2a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "703"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai.total_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okqqoe7lcqUH"
      },
      "source": [
        "In all, it took ~33 seconds and utilized 704 tokens. But there's a lot of unnecessary natter in the output:\n",
        "\n",
        "- The conversational preamble before the code\n",
        "- Docstrings and code comments\n",
        "- A long explanation of the code which may be redundant to the above\n",
        "\n",
        "All this natter adds latency and cost.\n",
        "\n",
        "There's a few techniques we can do with simpleaichat especially with the system prompt to mitigate these concerns, and therefore get a massive speedup:\n",
        "\n",
        "- Tell ChatGPT to ONLY generate code. Due to its RLHF training it sometimes doesn't always abide by it.\n",
        "- Tell ChatGPT to not output code comments.\n",
        "- Add a `stop` parameter to stop generating when the code encounters the final 3 backticks, skipping the explanation. Due to tokenization these could be followed by a space or a newline.\n",
        "\n",
        "Now, for the new `system` prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iA9AASKfacCH"
      },
      "outputs": [],
      "source": [
        "system_optimized = \"\"\"You are a Python code example.\n",
        "\n",
        "Follow ALL the following rules:\n",
        "- ONLY EVER RESPOND WITH CODE IN PYTHON MARKDOWN BLOCKS, AND NOTHING ELSE\n",
        "- NEVER include code comments.\"\"\"\n",
        "\n",
        "new_params = {\n",
        "    \"temperature\": 0.0,\n",
        "    \"stop\": [\"``` \", \"```\\n\"]\n",
        "}\n",
        "\n",
        "ai_2 = AIChat(api_key=api_key, system=system_optimized, model=model, params=new_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRYfniAXacCI",
        "outputId": "9528a719-711f-404c-eb9b-a57bcdf13af1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "def is_palindrome(word):\n",
            "    return word == word[::-1]\n",
            "```\n",
            "CPU times: user 3.86 ms, sys: 1.79 ms, total: 5.65 ms\n",
            "Wall time: 1.29 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = ai_2(\"is_palindrome\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGJr-GfIacCI",
        "outputId": "4ca7405a-bef6-455b-c1b1-685661cfd4a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "def is_palindrome(word):\n",
            "    length = len(word)\n",
            "    for i in range(length // 2):\n",
            "        if word[i] != word[length - i - 1]:\n",
            "            return False\n",
            "    return True\n",
            "\n",
            "CPU times: user 4.17 ms, sys: 2.18 ms, total: 6.35 ms\n",
            "Wall time: 2.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = ai_2(\"Make it more efficient.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eMDXGysacCJ",
        "outputId": "3f07561f-cc6e-443d-9e98-b28e1c556397"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "204"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_2.total_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua28VqKteKkr"
      },
      "source": [
        "~6 seconds total with 197 tokens used: that's 5x faster at 1/3 the cost!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaE3ftkMacCJ"
      },
      "source": [
        "## Create a Function\n",
        "\n",
        "Now we can create a function to automate the two calls we did above for any arbitrary input.\n",
        "\n",
        "For each call, we'll create an independent temporary session within simpleaichat and then clean it up. We'll also use a regex to strip unneded backticks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mN_-3fwuacCL"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "import re\n",
        "\n",
        "ai_func = AIChat(api_key=api_key, console=False)\n",
        "pattern = r\"```python\\n|```$\"\n",
        "def gen_code(query):\n",
        "    id = uuid4()\n",
        "    ai_func.new_session(api_key=api_key, id=id, system=system_optimized, params=new_params, model=model)\n",
        "    _ = ai_func(query, id=id)\n",
        "    response_optimized = ai_func(\"Make it more efficient.\", id=id)\n",
        "    \n",
        "    response_cleaned = re.sub(pattern, \"\", response_optimized).strip()\n",
        "    \n",
        "    ai_func.delete_session(id=id)\n",
        "    return response_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIkdpBwOacCL",
        "outputId": "6a5a6029-57ae-4872-c749-3d16da5bdd28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "def is_palindrome(word):\n",
            "    for i in range(len(word)//2):\n",
            "        if word[i] != word[-i-1]:\n",
            "            return False\n",
            "    return True\n",
            "CPU times: user 35.4 ms, sys: 1.07 ms, total: 36.4 ms\n",
            "Wall time: 5.13 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "code = gen_code(\"is_palindrome\")\n",
        "print(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1LjZjFBacCM",
        "outputId": "20acf718-92bc-4917-b779-f6baa4b0f7ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "string = \"hello world\"\n",
            "reverse_string = ''.join(reversed(string))\n",
            "print(reverse_string)\n",
            "CPU times: user 29 ms, sys: 2.19 ms, total: 31.2 ms\n",
            "Wall time: 4.04 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "code = gen_code(\"reverse string\")\n",
        "print(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdSNUiapacCM",
        "outputId": "ba92c813-c0aa-471b-d251-8ac30e1875d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "def fibonacci(n):\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    else:\n",
            "        a, b = 0, 1\n",
            "        for i in range(1, n):\n",
            "            a, b = b, a + b\n",
            "        return b\n",
            "CPU times: user 44.5 ms, sys: 5.46 ms, total: 49.9 ms\n",
            "Wall time: 7.91 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "code = gen_code(\"fibonacci\")\n",
        "print(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ppyZrFTacCM",
        "outputId": "33e95ae3-8e05-4b22-e459-c811c080b14e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "async def fibonacci(n: int, memo={}) -> int:\n",
            "    if n in memo:\n",
            "        return memo[n]\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    memo[n] = await fibonacci(n-1, memo) + await fibonacci(n-2, memo)\n",
            "    return memo[n]\n",
            "CPU times: user 43.2 ms, sys: 10.6 ms, total: 53.9 ms\n",
            "Wall time: 8.72 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "code = gen_code(\"async fibonacci\")\n",
        "print(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNQhAKFqacCM",
        "outputId": "1333ff8c-290a-4064-bed1-3569aeb80a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "import hashlib\n",
            "import multiprocessing\n",
            "\n",
            "def hash_string(string):\n",
            "    return hashlib.sha256(string.encode()).hexdigest()\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    strings = ['hello', 'world', 'python', 'multiprocessing']\n",
            "    with multiprocessing.Pool() as pool:\n",
            "        hashes = pool.map_async(hash_string, strings)\n",
            "        hashes.wait()\n",
            "        result = hashes.get()\n",
            "    print(result)\n",
            "CPU times: user 64.8 ms, sys: 4.9 ms, total: 69.7 ms\n",
            "Wall time: 11.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "code = gen_code(\"multiprocess hash\")\n",
        "print(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-QaAsRXbhAj"
      },
      "source": [
        "## MIT License\n",
        "\n",
        "Copyright (c) 2023 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
